import warnings
import numpy as np
import pandas as pd

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score, cross_val_predict, train_test_split
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import SequentialFeatureSelector, RFE
from sklearn.inspection import permutation_importance

warnings.filterwarnings("ignore")

data_path="/content/train.csv"
df=pd.read_csv(data_path)
X=df[["X1","X2","X3","X4","X5","X6"]]
y=df["Y"].astype(int)

majority=int(y.value_counts().idxmax())
baseline_acc=(y == majority).mean()
print(f"Majority class: {majority}")
print(f"Baseline accuracy: {baseline_acc:.4f}")

cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

pipe=Pipeline([
    ("scaler", StandardScaler(with_mean=True, with_std=True)),
    ("linreg", LinearRegression())
])

y_pred_scores=cross_val_predict(pipe,X,y,cv=cv,method="predict")
y_pred_scores=np.clip(y_pred_scores,0,1)
y_pred=(y_pred_scores >= 0.5).astype(int)

print(f"Accuracy: {accuracy_score(y,y_pred):.4f}")
print(confusion_matrix(y,y_pred))
print(f"ROC:{roc_auc_score(y,y_pred)}")
print(f"F1:{f1_score(y,y_pred)}")






log_reg=LogisticRegression(max_iter=5000,class_weight="balanced",solver="saga",penalty="elasticnet",l1_ratio=0.5)
pipe_lr=Pipeline([("scaler",StandardScaler()),("clf", log_reg)])
scores=cross_val_score(pipe_lr,X,y,cv=cv,scoring="accuracy",n_jobs=-1)
print(f"ElasicNet accuracy: {scores.mean():.4f} ± {scores.std():.4f}")



mlp=MLPClassifier(hidden_layer_sizes=(16,8),learning_rate_init=1e-3,activation="relu", max_iter=500,early_stopping=True,random_state=42)
pipe_mlp=Pipeline([("scaler",StandardScaler()),("clf",mlp)])
scores_mlp=cross_val_score(pipe_mlp,X,y,cv=cv,scoring="accuracy")
print(f"MLP accuracy: {scores_mlp.mean():.4f} ± {scores_mlp.std():.4f}")



log_l1=LogisticRegression(max_iter=5000,class_weight="balanced",solver="saga",penalty="l1")
pipe_fs=Pipeline([("scaler",StandardScaler()),("clf", log_l1)])
pipe_fs.fit(X,y)
coef=pipe_fs.named_steps["clf"].coef_.ravel()
selected=[col for col,c in zip(X.columns,coef) if abs(c) > 1e-8]
print("features", selected)



X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.26,stratify=y,random_state=42)
pipe_lr.fit(X_train,y_train)
perm=permutation_importance(pipe_fs,X_test,y_test,n_repeats=20,random_state=42,scoring="accuracy")
importances=pd.Series(perm.importances_mean, index=X.columns).sort_values(ascending=False)
print(f"importances: {importances}")


pipe_mlp.fit(X_train,y_train)
pipe_mlp.predict(X_test)
mlp_test_score=accuracy_score(y_test,pipe_mlp.predict(X_test))
print(f"mlp test accuracy: {mlp_test_score}")

log_reg.fit(X_train,y_train)
log_test_score=accuracy_score(y_test,log_reg.predict(X_test))
print(f"log test accuracy: {log_test_score}")





Majority class: 1
Baseline accuracy: 0.5476
Accuracy: 0.5397
[[21 36]
 [22 47]]
ROC:0.524790236460717
F1:0.618421052631579
ElasicNet accuracy: 0.5558 ± 0.0472
MLP accuracy: 0.5872 ± 0.0985
features ['X1', 'X2', 'X3', 'X5', 'X6']
importances: X1    0.118182
X2    0.000000
X4    0.000000
X3   -0.019697
X6   -0.019697
X5   -0.036364
dtype: float64
mlp test accuracy: 0.6363636363636364
log test accuracy: 0.7272727272727273





from google.colab import files
uploaded = files.upload() 


Given the six existing problems and limited sample size, any linear or shallow model would struggle to achieve 73% under a stable 10-CV. 
While ElasticNet outperformed on some splits, it failed to generalize globally. 
This isn't a parameter tuning issue, but rather a problem of insufficient information and label noise.
The Elastic Net coefficient and L1 sparsification tell which problems contribute the most








